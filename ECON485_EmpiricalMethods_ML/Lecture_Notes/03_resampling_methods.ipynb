{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Methods\n",
    "* two most commonly used resampling Methods\n",
    "\n",
    "(1) cross-validation\n",
    "\n",
    "(2) bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "lprice     float32\nlland      float32\nlarea      float32\nnbh       category\nrooms     category\ncbd        float32\ny81       category\nldist      float32\nbaths      float32\nage        float32\nagesq      float32\ndtype: object"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# download dataset to use throughout\n",
    "hprice3 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice3.dta')\n",
    "\n",
    "# pre-processing dataset\n",
    "## select interested columns\n",
    "col = ['lprice','lland','larea','nbh','rooms','cbd','y81','ldist','baths','age','agesq']\n",
    "df = hprice3[col]\n",
    "\n",
    "## change y81 and nbh to integers\n",
    "df[['y81','nbh', 'rooms']] = df[['y81','nbh','rooms']].astype(int) \n",
    "\n",
    "## change y81, nbh, rooms into categorical\n",
    "df['y81'] = df['y81'].astype('category')\n",
    "df['nbh'] = df['nbh'].astype(CategoricalDtype(ordered=False))\n",
    "df['rooms'] = df['rooms'].astype(CategoricalDtype(ordered=True))\n",
    "\n",
    "# view columns types of pre-processed dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "* these methods are used to do two things\n",
    "\n",
    "(1) Model Assessment: process of evaluating a model's performance\n",
    "\n",
    "(2) Model Selection: process of selecting the proper level of flexibility for a model\n",
    "\n",
    "* since models are 'trained' using training data sets, they are suitable to fit data in these training data sets only\n",
    "\n",
    "* since the validation set was not used to fit the model, these set of observations can be used to assess the performance of the model; therefore they allow us to do model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['lprice', 'lland', 'larea', 'cbd', 'ldist', 'baths', 'age', 'agesq',\n       'y81_1', 'nbh_1', 'nbh_2', 'nbh_3', 'nbh_4', 'nbh_5', 'nbh_6',\n       'rooms_5', 'rooms_6', 'rooms_7', 'rooms_8', 'rooms_9', 'rooms_10'],\n      dtype='object')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue preprocessing: convert categorical variables into dummy variables\n",
    "df1 = pd.get_dummies(df, columns=['y81', 'nbh','rooms'], drop_first = True)\n",
    "\n",
    "# get list of columns\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Approach\n",
    "\n",
    "![](img\\validation_set_approach.png)\n",
    "\n",
    "* set of n observations are randomly split into a training set (in blue with other obs) and a validation set (in beige containing other obs)\n",
    "\n",
    "* the stat learning method is fit onto the training set\n",
    "\n",
    "* performance evaluated on the validation set\n",
    "\n",
    "* can be doing many (i.e j) times randomly, then all model assessment measures such as RMSE, R2, Cp, BIC, and AIC can be calculated many (i.e j) times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "lprice\n0    11.00210\n1    10.59663\n2    10.43412\n3    11.06507\n4    10.69195\n..        ...\n316  11.00210\n317  11.88103\n318  11.48247\n319  11.46163\n320  12.22627\n\n[321 rows x 1 columns]\n"
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d9e03b585fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# run regression and do fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not sure how to fix error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# predict testing set with training set regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1532\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import patsy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# separate dataframe while preserving datatypes (pmatrices disregards categorical variables)\n",
    "X = df1[list(df1[1:21])]\n",
    "y = df1[['lprice']]\n",
    "\n",
    "# do validation set splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# run regression and do fit\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train) # not sure how to fix error\n",
    "\n",
    "# predict testing set with training set regression\n",
    "reg.score(X_test, Y_test)\n",
    "\n",
    "# create specification using dataframe column object -  not sure if I need\n",
    "predictors = \" + \".join(list(df1.columns[1:15]))\n",
    "f = \" ~ \".join(['lprice',predictors])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation\n",
    "\n",
    "![](img\\LOOCV.png)\n",
    "\n",
    "* set of n data points is repeatedly split into a training set (blue) containing all but one observation\n",
    "\n",
    "* validation set contains only that observation\n",
    "\n",
    "* test error calculated by averaging the n resulting MSE\n",
    "\n",
    "* total of n training data sets containing exactly n-1 observations has been constructed along with n corresponding validation data sets containing exactly 1 observation each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.18585808324152028, 0.1846562050869726, 0.18653729976416675, 0.1859217444741523, 0.19069844354607984]\n"
    }
   ],
   "source": [
    "# from assignment 3 - bring out betas of the regression\n",
    "import sklearn.linear_model as skm\n",
    "import sklearn.model_selection as sks\n",
    "\n",
    "# load ceosal2 \n",
    "ceosal2 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/ceosal2.dta')\n",
    "\n",
    "# covert ceosal2 from dataframe to array\n",
    "ceosal2_array = ceosal2.to_numpy()\n",
    "\n",
    "# define a string with regression equation\n",
    "eq = 'lsalary ~ lsales + lmktval + profmarg + comten + comtensq + ceoten + ceotensq + age + college + grad'\n",
    "\n",
    "# build a design matrix with the formula\n",
    "y,X = patsy.dmatrices(eq, data = ceosal2, return_type='dataframe')\n",
    "\n",
    "# create empty list to store LeaveOutOne betas\n",
    "betas = []\n",
    "\n",
    "# run LeaveOneOut cross validation\n",
    "loo = sks.LeaveOneOut()\n",
    "for train, test in loo.split(ceosal2_array):\n",
    "    # run a regression and obtain beta for lsales\n",
    "    beta_value = float((skm.LinearRegression().fit(X.loc[train],y.loc[train]).coef_)[:,1])\n",
    "    \n",
    "    # store beta value as a float\n",
    "    betas.append(beta_value)\n",
    "\n",
    "# print first six betas\n",
    "print(betas[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold Cross-Validation\n",
    "\n",
    "![](img\\k_fold_CV.png)\n",
    "\n",
    "* set of n observations is randomly split into five non-overlapping groups\n",
    "\n",
    "* each of these fifths acts as a validation set (beige) and the remainder as a training set (blue)\n",
    "\n",
    "* test error is estimated by averaging the five resulting MSE estimates\n",
    "\n",
    "* approach involves randomly dividing the set of observations into k groups (called folds) of approximately equal size\n",
    "\n",
    "* first fold = validation set, method is fit on the remaining k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from assignment 4 - only displaying how to set up kFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import hprice1 dataset\n",
    "hprice1 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice1.dta')\n",
    "\n",
    "# change hprice1 from dataframe to array for kfold \n",
    "hprice1_array = hprice1.to_numpy()\n",
    "\n",
    "# create kfold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# split data into 10 folds and collect RSS values\n",
    "for train_index, test_index in kf.split(hprice1_array):\n",
    "    # divide dataframe into test and train\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]"
   ]
  }
 ]
}