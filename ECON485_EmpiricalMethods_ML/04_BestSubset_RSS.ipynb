{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Empirical Assignment 4</h1></center>\n",
    "\n",
    "**Author(s):**\n",
    "1. Belicia Rodriguez (belicia.rodriguez@emory.edu)\n",
    "\n",
    "**Objectives**: This <ins>assignment</ins> aims at\n",
    " 1. Learning how to adapt other people's code to one needs;\n",
    " 2. Use *GitHub* to retrieve and submit computer code.\n",
    "\n",
    "**Instructions**:\n",
    " 1. Please write down your Python code and <ins>execute</ins> it in the cell below each question.\n",
    " \n",
    " **Data Source**: [Introductory Econometrics: A Modern Approach](https://cran.r-project.org/web/packages/wooldridge/index.html) by Jeffrey Wooldridge\n",
    "\n",
    "**Data Description**: ```http://fmwww.bc.edu/ec-p/data/wooldridge/hprice1.dta```\n",
    "\n",
    "```\n",
    "Contains data from hprice1.dta\n",
    "  obs:            88                          \n",
    " vars:            10                          17 Mar 2002 12:21\n",
    " size:         3,168 (99.5% of memory free)\n",
    "-------------------------------------------------------------------------------\n",
    "              storage  display     value\n",
    "variable name   type   format      label      variable label\n",
    "-------------------------------------------------------------------------------\n",
    "price           float  %9.0g                  house price, $1000s\n",
    "assess          float  %9.0g                  assessed value, $1000s\n",
    "bdrms           byte   %9.0g                  number of bdrms\n",
    "lotsize         float  %9.0g                  size of lot in square feet\n",
    "sqrft           int    %9.0g                  size of house in square feet\n",
    "colonial        byte   %9.0g                  =1 if home is colonial style\n",
    "lprice          float  %9.0g                  log(price)\n",
    "lassess         float  %9.0g                  log(assess\n",
    "llotsize        float  %9.0g                  log(lotsize)\n",
    "lsqrft          float  %9.0g                  log(sqrft)\n",
    "-------------------------------------------------------------------------------\n",
    "Sorted by:  \n",
    " ```\n",
    " \n",
    " **Background**: Consider the general model\n",
    " \n",
    " $$\n",
    "\\begin{aligned}\n",
    "\\texttt{lprice} &= \\beta_{0} + \\beta_{1}\\texttt{llotsize} +  \\beta_{2}\\texttt{lsqrft} +\\beta_{3}\\texttt{colonial}+\\beta_{4}\\texttt{bdrms}\\\\\n",
    "&+ \\beta_{5}\\texttt{colonial}\\times\\texttt{llotsize}+ \\beta_{6}\\texttt{colonial}\\times\\texttt{lsqrft}++ \\beta_{7}\\texttt{colonial}\\times\\texttt{bdrms}+ e.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "You now know that a relatively unknown _alternative_ measure of fit, $\\widetilde{R}^2$, is defined as\n",
    "\n",
    "$$\n",
    "\\widetilde{R}^{2}=1-\\frac{\\sum_{i=1}^{n} \\widetilde{e}_{i}^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y}\\right)^{2}},\n",
    "$$\n",
    "\n",
    "where $\\{\\widetilde{e}_i;i=1,\\dots,n\\}$ are the _prediction errors_ previously discussed in class, and $\\{y_i;i=1,\\dots,n\\}$ represents the elements $\\{\\texttt{lprice} _i;i=1,\\dots,n\\}$ in the ```hprice1``` data set. Recall that $\\widetilde{R}^2$ estimates the percentage of the forecast variance which is explained by the regression forecast. You think this is a better measure of _fitness_ than the $RSS$ or the classical $R^2$.\n",
    " \n",
    "<center><h2> Questions</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [15 points] Proceed to modify the previously defined ```processSubset``` Python function so it returns this new quantity $\\widetilde{R}^2$ instead of the $RSS$ (called ```ssr``` by the ```statsmodels``` library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "# redefine processSubset to calculate new R^2\n",
    "def processSubset(feature_set):\n",
    "    # fit model on feature_set\n",
    "    model = OLS(y,X[list(feature_set)])\n",
    "    reg = model.fit()\n",
    "    \n",
    "    # calculate new R^2\n",
    "    predict_errors = ((reg.resid/(1 - reg.get_influence().hat_matrix_diag))**2).sum()\n",
    "    sum_of_squares = (reg.centered_tss)\n",
    "    R2 = 1 - (predict_errors/sum_of_squares)\n",
    "    \n",
    "    return {'model':reg, 'new R2':R2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [35 points] Using the entire set of 88 observations proceed to find out all the best 7 specifications using the **Best Subset Selection** algorithm discussed in class that utilizes the proposed $\\widetilde{R}^2$ measure of fit instead. *Note*: All these 7 specifications must contain an intercept per our discussion in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               model    new R2\n",
      "1  <statsmodels.regression.linear_model.Regressio...  0.538504\n",
      "2  <statsmodels.regression.linear_model.Regressio...  0.613883\n",
      "3  <statsmodels.regression.linear_model.Regressio...  0.613524\n",
      "4  <statsmodels.regression.linear_model.Regressio...  0.607329\n",
      "5  <statsmodels.regression.linear_model.Regressio...  0.590002\n",
      "6  <statsmodels.regression.linear_model.Regressio...  0.564622\n",
      "7  <statsmodels.regression.linear_model.Regressio...  0.471542\n"
     ]
    }
   ],
   "source": [
    "# import hprice1 dataset\n",
    "hprice1 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice1.dta')\n",
    "\n",
    "# create design matrix of specification\n",
    "f = 'lprice ~ llotsize + lsqrft + colonial + bdrms + colonial:llotsize + colonial:lsqrft + colonial:bdrms'\n",
    "y,X = patsy.dmatrices(f, data=hprice1, return_type='dataframe')\n",
    "\n",
    "# demean outcome and features: subtract sample mean from each observation\n",
    "y = y.sub(y.mean())\n",
    "X = X.sub(X.mean()).drop('Intercept', axis=1)\n",
    "\n",
    "# define getBest function\n",
    "def getBest(p):\n",
    "    # create empty array to store results\n",
    "    results = []\n",
    "    \n",
    "    # \n",
    "    for combo in itertools.combinations(X.columns,p):\n",
    "        results.append(processSubset(combo))\n",
    "\n",
    "    # put results in dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # choose model with lowest new R^2\n",
    "    best_model = models.loc[models['new R2'].argmax()]\n",
    "    return best_model\n",
    "\n",
    "# collect the best models using a loop\n",
    "models_best = pd.DataFrame(columns=['model','new R2'])\n",
    "\n",
    "for i in range(1,8):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "    \n",
    "print(models_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** pay attention to the warning and use idxmax instead of argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [50 points] For each of the best 7 specifications you found to maximize the forecast variance that is explained by the regression forecast in the previous question, proceed to calculate the cross-validated errors in a $10$-fold (using a seed equal to $42$). For example, let's assume that the best model that includes just one regressor using the entire sample of 88 observations and the $\\widetilde{R}^2$ is the model that regresses ```lprice``` on ```colonial```. Using the partition of the first fold, proceed to use the 90% of the observations to fit this model and then predict the ```lprice``` in the remaining 10% in this fold, and modified *again* your ```processSubset``` function to return the RSS, see, e.g., the Python code in the lecture notes. Save this value and then do the same for the next fold, save this value, and continue doing it till you have 10 RSS values corresponding to the $10$-fold. Average these 10 values and save it. Then do the same with the best model you found that contains 2 regressors, then the best that contains 3 regressors, and so on till you do the same for the complete model with 7 features. Plot these average values and proceed to report the model with the *smallest* cross-validated error. Then fit (```.summary()```) this *best* model using the entire sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>lprice</td>      <th>  R-squared (uncentered):</th>      <td>   0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   52.94</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Mar 2020</td> <th>  Prob (F-statistic):</th>          <td>2.13e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:50:23</td>     <th>  Log-Likelihood:    </th>          <td>  26.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    88</td>      <th>  AIC:               </th>          <td>  -47.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    85</td>      <th>  BIC:               </th>          <td>  -40.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>llotsize</th>       <td>    0.1663</td> <td>    0.038</td> <td>    4.422</td> <td> 0.000</td> <td>    0.092</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lsqrft</th>         <td>    0.7287</td> <td>    0.081</td> <td>    9.010</td> <td> 0.000</td> <td>    0.568</td> <td>    0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>colonial:bdrms</th> <td>    0.0212</td> <td>    0.011</td> <td>    1.981</td> <td> 0.051</td> <td>-8.12e-05</td> <td>    0.042</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.054</td> <th>  Durbin-Watson:     </th> <td>   2.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  53.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.032</td> <th>  Prob(JB):          </th> <td>1.97e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.834</td> <th>  Cond. No.          </th> <td>    7.87</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                 lprice   R-squared (uncentered):                   0.651\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.639\n",
       "Method:                 Least Squares   F-statistic:                              52.94\n",
       "Date:                Thu, 05 Mar 2020   Prob (F-statistic):                    2.13e-19\n",
       "Time:                        11:50:23   Log-Likelihood:                          26.912\n",
       "No. Observations:                  88   AIC:                                     -47.82\n",
       "Df Residuals:                      85   BIC:                                     -40.39\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "llotsize           0.1663      0.038      4.422      0.000       0.092       0.241\n",
       "lsqrft             0.7287      0.081      9.010      0.000       0.568       0.890\n",
       "colonial:bdrms     0.0212      0.011      1.981      0.051   -8.12e-05       0.042\n",
       "==============================================================================\n",
       "Omnibus:                       14.054   Durbin-Watson:                   2.064\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               53.903\n",
       "Skew:                           0.032   Prob(JB):                     1.97e-12\n",
       "Kurtosis:                       6.834   Cond. No.                         7.87\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# modify processSubset function to return RSS\n",
    "def processFold(r, X_train, X_test, y_train, y_test):    \n",
    "    # run OLS and fit a regression\n",
    "    model = sm.OLS(y_train, X_train[list(r)])\n",
    "    regr = model.fit()\n",
    "    \n",
    "    # predict test set and calculate RSS\n",
    "    RSS = ((regr.predict(X_test[list(r)]) - y_test.iloc[:,0])**2).sum()\n",
    "\n",
    "    return RSS\n",
    "\n",
    "# run a kFold and get the RSS of each fold, then calculate the average of RSS\n",
    "def runKfold_getavgRSS(i):\n",
    "    # itialize empty array\n",
    "    RSS = []\n",
    "\n",
    "    # split data into 10 folds and collect RSS values\n",
    "    for train_index, test_index in kf.split(hprice1_array):\n",
    "        # divide dataframe into test and train\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "    \n",
    "        # define which regressor(s) to analyze\n",
    "        regressor = models_best['model'][i].model.exog_names\n",
    "    \n",
    "        # send to processFold to get RSS\n",
    "        rss_value = processFold(regressor, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "        # append RSS value to \n",
    "        RSS.append(rss_value)\n",
    "    \n",
    "    # take average of the RSS collected in the kFold\n",
    "    RSS_avg_value = np.mean(RSS)\n",
    "    \n",
    "    return RSS_avg_value\n",
    "\n",
    "# create kfold object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# change hprice1 from dataframe to array for kfold \n",
    "hprice1_array = hprice1.to_numpy()\n",
    "\n",
    "# initiate an empty list\n",
    "RSS_avgs = pd.DataFrame(columns=['R2'], index=range(1,8), dtype='float64')\n",
    "\n",
    "# run a loop to go through each best model and collect the RSS averages\n",
    "for i in (range(1,8)):\n",
    "    a = runKfold_getavgRSS(i)\n",
    "    RSS_avgs.loc[i] = a\n",
    "    \n",
    "# create graph of RSS averages\n",
    "plt.plot(RSS_avgs)\n",
    "plt.show()\n",
    "\n",
    "# choose model with lowest error\n",
    "smallest = RSS_avgs['R2'].argmin()\n",
    "\n",
    "# display summary of the model\n",
    "models_best['model'][smallest].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** again, be careful with the warnings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
