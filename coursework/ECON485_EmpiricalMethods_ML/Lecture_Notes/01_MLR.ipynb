{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit88832310db0f46c6ba1b97f6fce48e8e",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Model\n",
    "I will review the following topics:\n",
    "* The Algebra of the OLS Estimator\n",
    "* Asymptotic Properties of the OLS Estimator\n",
    "* Regression Intervals\n",
    "* Forecast Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import patsy\n",
    "\n",
    "# download dataset to use throughout\n",
    "hprice2 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice2.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table class=\"simpletable\">\n<tr>\n        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>     <td>0.763</td>  \n</tr>\n<tr>\n  <td>Dependent Variable:</td>      <td>lprice</td>             <td>AIC:</td>         <td>-188.7488</td>\n</tr>\n<tr>\n         <td>Date:</td>        <td>2020-03-08 19:20</td>        <td>BIC:</td>         <td>-150.7100</td>\n</tr>\n<tr>\n   <td>No. Observations:</td>         <td>506</td>         <td>Log-Likelihood:</td>    <td>103.37</td>  \n</tr>\n<tr>\n       <td>Df Model:</td>              <td>8</td>           <td>F-statistic:</td>       <td>204.8</td>  \n</tr>\n<tr>\n     <td>Df Residuals:</td>           <td>497</td>       <td>Prob (F-statistic):</td> <td>5.77e-152</td>\n</tr>\n<tr>\n      <td>R-squared:</td>            <td>0.767</td>            <td>Scale:</td>        <td>0.039616</td> \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n</tr>\n<tr>\n  <th>Intercept</th> <td>12.6516</td>  <td>0.3473</td>   <td>36.4288</td> <td>0.0000</td> <td>11.9693</td> <td>13.3340</td>\n</tr>\n<tr>\n  <th>lnox</th>      <td>-0.4503</td>  <td>0.0920</td>   <td>-4.8937</td> <td>0.0000</td> <td>-0.6311</td> <td>-0.2695</td>\n</tr>\n<tr>\n  <th>lproptax</th>  <td>-0.2274</td>  <td>0.0477</td>   <td>-4.7634</td> <td>0.0000</td> <td>-0.3212</td> <td>-0.1336</td>\n</tr>\n<tr>\n  <th>crime</th>     <td>-0.0113</td>  <td>0.0014</td>   <td>-8.2754</td> <td>0.0000</td> <td>-0.0139</td> <td>-0.0086</td>\n</tr>\n<tr>\n  <th>rooms</th>     <td>0.0990</td>   <td>0.0168</td>   <td>5.9008</td>  <td>0.0000</td> <td>0.0660</td>  <td>0.1320</td> \n</tr>\n<tr>\n  <th>dist</th>      <td>-0.0488</td>  <td>0.0073</td>   <td>-6.6939</td> <td>0.0000</td> <td>-0.0631</td> <td>-0.0345</td>\n</tr>\n<tr>\n  <th>radial</th>    <td>0.0115</td>   <td>0.0023</td>   <td>5.0277</td>  <td>0.0000</td> <td>0.0070</td>  <td>0.0160</td> \n</tr>\n<tr>\n  <th>stratio</th>   <td>-0.0404</td>  <td>0.0050</td>   <td>-8.1325</td> <td>0.0000</td> <td>-0.0502</td> <td>-0.0307</td>\n</tr>\n<tr>\n  <th>lowstat</th>   <td>-0.0283</td>  <td>0.0019</td>  <td>-14.7579</td> <td>0.0000</td> <td>-0.0320</td> <td>-0.0245</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td>Omnibus:</td>    <td>60.676</td>  <td>Durbin-Watson:</td>    <td>1.047</td> \n</tr>\n<tr>\n  <td>Prob(Omnibus):</td>  <td>0.000</td> <td>Jarque-Bera (JB):</td> <td>204.257</td>\n</tr>\n<tr>\n       <td>Skew:</td>      <td>0.517</td>     <td>Prob(JB):</td>      <td>0.000</td> \n</tr>\n<tr>\n     <td>Kurtosis:</td>    <td>5.936</td>  <td>Condition No.:</td>    <td>1090</td>  \n</tr>\n</table>",
      "text/plain": "<class 'statsmodels.iolib.summary2.Summary'>\n\"\"\"\n                 Results: Ordinary least squares\n==================================================================\nModel:              OLS              Adj. R-squared:     0.763    \nDependent Variable: lprice           AIC:                -188.7488\nDate:               2020-03-08 19:20 BIC:                -150.7100\nNo. Observations:   506              Log-Likelihood:     103.37   \nDf Model:           8                F-statistic:        204.8    \nDf Residuals:       497              Prob (F-statistic): 5.77e-152\nR-squared:          0.767            Scale:              0.039616 \n-------------------------------------------------------------------\n               Coef.   Std.Err.     t      P>|t|    [0.025   0.975]\n-------------------------------------------------------------------\nIntercept     12.6516    0.3473   36.4288  0.0000  11.9693  13.3340\nlnox          -0.4503    0.0920   -4.8937  0.0000  -0.6311  -0.2695\nlproptax      -0.2274    0.0477   -4.7634  0.0000  -0.3212  -0.1336\ncrime         -0.0113    0.0014   -8.2754  0.0000  -0.0139  -0.0086\nrooms          0.0990    0.0168    5.9008  0.0000   0.0660   0.1320\ndist          -0.0488    0.0073   -6.6939  0.0000  -0.0631  -0.0345\nradial         0.0115    0.0023    5.0277  0.0000   0.0070   0.0160\nstratio       -0.0404    0.0050   -8.1325  0.0000  -0.0502  -0.0307\nlowstat       -0.0283    0.0019  -14.7579  0.0000  -0.0320  -0.0245\n------------------------------------------------------------------\nOmnibus:              60.676       Durbin-Watson:          1.047  \nProb(Omnibus):        0.000        Jarque-Bera (JB):       204.257\nSkew:                 0.517        Prob(JB):               0.000  \nKurtosis:             5.936        Condition No.:          1090   \n==================================================================\n* The condition number is large (1e+03). This might indicate\nstrong multicollinearity or other numerical problems.\n\"\"\""
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view first six rows of the dataset\n",
    "hprice2.head()\n",
    "\n",
    "# view data information such as count, mean, max, etc\n",
    "hprice2.describe()\n",
    "\n",
    "# specify outcome variable (y) and regressors/predictors (x) using string\n",
    "f = 'lprice ~ lnox + lproptax + crime + rooms + dist + radial + stratio + lowstat'\n",
    "\n",
    "# select columns of the dataframe as an attribute (or using brackets) - creates panda series\n",
    "hprice2.crime\n",
    "hprice2['crime']\n",
    "\n",
    "# use double brackets to select columns as a dataframe\n",
    "hprice2[['crime', 'lnox']]\n",
    "\n",
    "# create a design matrix using patsy package\n",
    "y, X = patsy.dmatrices(f, data=hprice2, return_type='dataframe')\n",
    "\n",
    "# calculate OLS, fit model to a regression, then use summary to view\n",
    "model = OLS(y,X)\n",
    "reg = model.fit()\n",
    "reg.summary()\n",
    "reg.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>y_hat</th>\n      <th>e_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.085810</td>\n      <td>10.303026</td>\n      <td>-0.217217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.980402</td>\n      <td>10.145426</td>\n      <td>-0.165024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.454500</td>\n      <td>10.365117</td>\n      <td>0.089383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.416310</td>\n      <td>10.330250</td>\n      <td>0.086060</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.496790</td>\n      <td>10.277121</td>\n      <td>0.219669</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           y      y_hat     e_hat\n0  10.085810  10.303026 -0.217217\n1   9.980402  10.145426 -0.165024\n2  10.454500  10.365117  0.089383\n3  10.416310  10.330250  0.086060\n4  10.496790  10.277121  0.219669"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary\n",
    "ols_var = {'y': hprice2.lprice, 'y_hat': reg.fittedvalues, 'e_hat': reg.resid}\n",
    "\n",
    "# print first six outcomes, fitted vales, and residuals\n",
    "ols_info = pd.DataFrame(ols_var)\n",
    "ols_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis of variance\n",
    "total sum of squares = explained sum of squares + residual sum of squares\n",
    "\n",
    "$\\sum_{i=1}^n (y_i - \\bar{y})^2 = \\sum_{i=1}^n (\\hat{y_i} + \\bar{y})^2 + \\sum_{i=1}^n \\hat{e_i}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "19.689097978248622"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view OLS total sum of squares, explained sum of squares, and residual sum of squares (statsmodel site down)\n",
    "reg.ssr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coefficient of determination ($R^2$)\n",
    "\n",
    "$R^2 = \\frac{\\sum_{i=1}^n (\\hat{y_i} - \\bar{y})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} = 1 - \\frac{\\sum_{i=1}^n \\hat{e_i}^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$\n",
    "\n",
    "* known as the square of sample correlation coefficient between the true and fitted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjusted $R^2$\n",
    "\n",
    "$\\bar{R^2} = 1 - \\frac{n\\sum_{i=1}^n \\hat{e_i}^2}{(n-k-1)\\sum_{i=1}^n (y_i - \\bar{y})^2}$ \n",
    "\n",
    "* unlike $R^2$ which cannot decrease as k increases, $\\bar{R^2}$ can either increase or decrease with k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.767219563142833\n0.7634725943403031\n"
    }
   ],
   "source": [
    "# view R2\n",
    "print(reg.rsquared)\n",
    "\n",
    "# view adjusted R2\n",
    "print(reg.rsquared_adj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leverage values (hii)\n",
    "* a measure of how far away the independent variable values of an observation are from those of the other observations\n",
    "* diagonal of hat matrix\n",
    "* hat matrix: the projection matrix that expresses the values of the observations in the independent variable, 𝐲, in terms of the linear combinations of the column vectors of the model matrix\n",
    "* This entry in the hat matrix will have a direct influence on the way entry $y_i$ will result in $\\hat{y_i}$( high-leverage of the 𝑖-th observation $y_i$ in determining its own prediction value $\\hat{y_i})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.00465546 0.00745928 0.01159636 0.01147143 0.01015461]\n"
    }
   ],
   "source": [
    "# create instance of influence\n",
    "reg_influence = reg.get_influence()\n",
    "\n",
    "# get leverage values\n",
    "hii = reg_influence.hat_matrix_diag\n",
    "print(hii[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction error (leave one out residual or prediction residual)\n",
    "\n",
    "$\\tilde{e_i} =  y_i - \\tilde{y_i}$ where $\\tilde{y_i}$ is the leave-one-out predicted value\n",
    "\n",
    "* there's a leave one out estimator for each value\n",
    "* to calculate $\\tilde{e_i}$ use the following:\n",
    "\n",
    "$\\tilde{e_i} = (1-h_{ii})^1 \\hat{e_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0     -0.219350\n1     -0.165796\n2      0.090055\n3      0.087070\n4      0.222218\n         ...   \n501    0.006959\n502   -0.057587\n503   -0.098375\n504   -0.127720\n505   -0.631556\nLength: 506, dtype: float64\n"
    }
   ],
   "source": [
    "# original OLS residual\n",
    "e_hat = reg.resid\n",
    "\n",
    "# calculate prediction error\n",
    "e_tilde = e_hat / (1-hii)\n",
    "\n",
    "# calculate OLS without 156 observation (later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of Error Variance\n",
    "* the unconditional error variance $\\sigma^2 = E[e_i^2]$ can be estimated as follows:\n",
    "\n",
    "(1) $s^2 = \\frac{1}{n-k-1} \\sum_{i=1}^n \\hat{e_i}^2$\n",
    "\n",
    "(2) $\\hat{\\sigma^2} = \\frac{1}{n} \\sum_{i=1}^n \\hat{e_i}^2$\n",
    " \n",
    "(3) $\\bar{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^n \\tilde{e_i}^2 = \\frac{1}{n} \\sum_{i=1}^n (1-h_{ii})^{-2} \\hat{e_i}^2$\n",
    "\n",
    "* when k\\n is small, any will do\n",
    "\n",
    "* when k\\n is big, use (1) or (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymptotic Properties of the OLS Estimator\n",
    "\n",
    "(will investigate more in depth at a later time)\n",
    "\n",
    "OLS Variance Estimation ($V_{\\hat{\\beta}}$)\n",
    "\n",
    "(1) HC0\n",
    "\n",
    "(2) HC1 - most common\n",
    "\n",
    "(3) HC2\n",
    "\n",
    "(4) HC3\n",
    "\n",
    "Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>11.969265</td>\n      <td>13.333970</td>\n    </tr>\n    <tr>\n      <th>lnox</th>\n      <td>-0.631135</td>\n      <td>-0.269532</td>\n    </tr>\n    <tr>\n      <th>lproptax</th>\n      <td>-0.321159</td>\n      <td>-0.133591</td>\n    </tr>\n    <tr>\n      <th>crime</th>\n      <td>-0.013940</td>\n      <td>-0.008591</td>\n    </tr>\n    <tr>\n      <th>rooms</th>\n      <td>0.066035</td>\n      <td>0.131961</td>\n    </tr>\n    <tr>\n      <th>dist</th>\n      <td>-0.063130</td>\n      <td>-0.034480</td>\n    </tr>\n    <tr>\n      <th>radial</th>\n      <td>0.006987</td>\n      <td>0.015951</td>\n    </tr>\n    <tr>\n      <th>stratio</th>\n      <td>-0.050183</td>\n      <td>-0.030654</td>\n    </tr>\n    <tr>\n      <th>lowstat</th>\n      <td>-0.032032</td>\n      <td>-0.024505</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                   0          1\nIntercept  11.969265  13.333970\nlnox       -0.631135  -0.269532\nlproptax   -0.321159  -0.133591\ncrime      -0.013940  -0.008591\nrooms       0.066035   0.131961\ndist       -0.063130  -0.034480\nradial      0.006987   0.015951\nstratio    -0.050183  -0.030654\nlowstat    -0.032032  -0.024505"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating vcov matrices\n",
    "\n",
    "# calculate 99% confidence interval\n",
    "reg.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate regression interval - figure out manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Interval\n",
    "* suppose we are given value of regressor vector $x_{n+1}$ for individual outside of sample and want to forecast $y_{n+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate forecast interval - figure out manually"
   ]
  }
 ]
}