{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Case Study 1</h1></center>\n",
    "<center><h3> Week 1 (out of 5)</h3></center>\n",
    "\n",
    "**Author(s):**\n",
    "1. Belicia Rodriguez (belicia.rodriguez@emory.edu)\n",
    " \n",
    "**Data Source**: W.C. Hunter and M.B. Walker (1996), [“*The Cultural Affinity Hypothesis and Mortgage Lending Decisions*,”](https://link.springer.com/article/10.1007/BF00174551) Journal of Real Estate Finance and Economics 13, 57-70.\n",
    " \n",
    "**Book**: [Introductory Econometrics: A Modern Approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) by Jeffrey Wooldridge\n",
    "\n",
    "**Data Description**: ```http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta```\n",
    "\n",
    "```\n",
    "  Obs:  1989\n",
    "\n",
    "  1. occ                       occupancy\n",
    "  2. loanamt                   loan amt in thousands\n",
    "  3. action                    type of action taken\n",
    "  4. msa                       msa number of property\n",
    "  5. suffolk                   =1 if property in Suffolk County\n",
    "  6. race                      race of applicant\n",
    "  7. gender                    gender of applicant\n",
    "  8. appinc                    applicant income, $1000s\n",
    "  9. typur                     type of purchaser of loan\n",
    " 10. unit                      number of units in property\n",
    " 11. married                   =1 if applicant married\n",
    " 12. dep                       number of dependents\n",
    " 13. emp                       years employed in line of work\n",
    " 14. yjob                      years at this job\n",
    " 15. self                      self-employment dummy\n",
    " 16. atotinc                   total monthly income\n",
    " 17. cototinc                  coapp total monthly income\n",
    " 18. hexp                      propose housing expense\n",
    " 19. price                     purchase price\n",
    " 20. other                     other financing, $1000s\n",
    " 21. liq                       liquid assets\n",
    " 22. rep                       no. of credit reports\n",
    " 23. gdlin                     credit history meets guidelines\n",
    " 24. lines                     no. of credit lines on reports\n",
    " 25. mortg                     credit history on mortgage paym\n",
    " 26. cons                      credit history on consumer stuf\n",
    " 27. pubrec                    =1 if filed bankruptcy\n",
    " 28. hrat                      housing exp, % total inccome\n",
    " 29. obrat                     other oblgs,  % total income\n",
    " 30. fixadj                    fixed or adjustable rate?\n",
    " 31. term                      term of loan in months\n",
    " 32. apr                       appraised value\n",
    " 33. prop                      type of property\n",
    " 34. inss                      PMI sought\n",
    " 35. inson                     PMI approved\n",
    " 36. gift                      gift as down payment\n",
    " 37. cosign                    is there a cosigner\n",
    " 38. unver                     unverifiable info\n",
    " 39. review                    number of times reviewed\n",
    " 40. netw                      net worth\n",
    " 41. unem                      unemployment rate by industry\n",
    " 42. min30                     =1 if minority pop. > 30%\n",
    " 43. bd                        =1 if boarded-up val > MSA med\n",
    " 44. mi                        =1 if tract inc > MSA median\n",
    " 45. old                       =1 if applic age > MSA median\n",
    " 46. vr                        =1 if tract vac rte > MSA med\n",
    " 47. sch                       =1 if > 12 years schooling\n",
    " 48. black                     =1 if applicant black\n",
    " 49. hispan                    =1 if applicant Hispanic\n",
    " 50. male                      =1 if applicant male\n",
    " 51. reject                    =1 if action == 3\n",
    " 52. approve                   =1 if action == 1 or 2\n",
    " 53. mortno                    no mortgage history\n",
    " 54. mortperf                  no late mort. payments\n",
    " 55. mortlat1                  one or two late payments\n",
    " 56. mortlat2                  > 2 late payments\n",
    " 57. chist                     =0 if accnts deliq. >= 60 days\n",
    " 58. multi                     =1 if two or more units\n",
    " 59. loanprc                   amt/price\n",
    " 60. thick                     =1 if rep > 2\n",
    " 61. white                     =1 if applicant white\n",
    " 62. obwhte                    obrat*awhite\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your new job as a data analyst, you have been given this data set and asked to _build_ a machine (in this case a **linear probability model**) to aid your client to automatize their loan approval decisions. Using your knowledge of the Ridge, Lasso, and Elastic Net estimators find an economic sound model with the smallest *mean squared errors* when 20% of the observations in this data set are kept to validate the proposed model using a seed equal to 42."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Things to consider:</h4>\n",
    "\n",
    "    1. Read the original paper to understand how the variables were constructed and the feature in their model.\n",
    "    2. Read section 7.4 titled \"Interactions Involving Dummy Variables\" in 'Introductory Econometrics: A Modern Approach' by Jeffrey Wooldridge.\n",
    "    3. Read section 7.5 titled \"A Binary Dependent Variable: The Linear Probability Model\" in 'Introductory Econometrics: A Modern Approach' by Jeffrey Wooldridge.\n",
    "    4. You should try standardizing as well as normalizing your chosen features when trying different estimators.\n",
    "    5. Always estimate an intercept.\n",
    "    6. Your answers should include the final chosen specification and the reported mean squared error of your validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# import dataset\n",
    "loanapp = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The dataset currently has all variables set as floats, and none of the variables are set to dummies. During preprocessing, I will construct dummy variables of the intersection of race and gender, and I will change the categorical variables in the dataset to dummy variables and drop the first level in the categorical variable in order to make constructing a model later easier (and prevent perfect collinearity). The last section then constructs demeaned and standardized versions of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# change numeric values in race and gender to their string representation\n",
    "for i in range(len(loanapp)):\n",
    "    # change race variables\n",
    "    if loanapp['race'][i] == 5:\n",
    "        loanapp['race'][i] = 'white'\n",
    "    elif loanapp['race'][i] == 4:\n",
    "        loanapp['race'][i] = 'black'\n",
    "    elif loanapp['race'][i] == 3:\n",
    "        loanapp['race'][i] = 'hispan'\n",
    "    \n",
    "    # change gender variables\n",
    "    if loanapp['gender'][i] == 1:\n",
    "        loanapp['gender'][i] = 'male'\n",
    "    elif loanapp['gender'][i] == 2:\n",
    "        loanapp['gender'][i] = 'female'\n",
    "    elif loanapp['gender'][i] == 3:\n",
    "        loanapp['gender'][i] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment:\n",
    "\n",
    "I do not see what is the advantage in changing the data type of the categorical variables to strings. If you are worried about the categories being ```float32```, you can change the type to integer (```int```). To change the type you can use, for instance ```loanapp['race'] = loanapp['race'].astype('int32')```. Also, pay attention to the warning ```SettingWithCopyWarning``` (here is a good explanation of it https://www.dataquest.io/blog/settingwithcopywarning/). Finally, if for some reason you really wanted to change the floats to strings, there is a faster way to do it. Instead of using a loop, you can use the ```loc``` function and try something like: ```loanapp.loc[loanapp.race==5,'race'] = 'white'``` and repeat the process for all the values. You could use loop to iterate along the possible values that race could take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all categorical variables in dataset\n",
    "cat = ['suffolk', 'married', 'self', 'pubrec', 'cosign', 'min30', 'bd', 'mi', 'old', 'vr', 'sch', 'black', 'hispan', 'male', 'reject', 'approve', 'mortno', 'mortperf', 'mortlat1', 'mortlat2', 'chist', 'multi', 'thick', 'white', 'inss', 'inson', 'fixadj', 'unver', 'gift', 'prop', 'occ', 'action']\n",
    "\n",
    "# convert all categorical variables to dummy variables\n",
    "loanapp = pd.get_dummies(loanapp, columns = cat, drop_first = True)\n",
    "loanapp = pd.get_dummies(loanapp, columns = ['race', 'gender'])\n",
    "\n",
    "# create race/gender dummy variables\n",
    "for r in ['race_black', 'race_hispan', 'race_white']:\n",
    "    for g in ['gender_female', 'gender_male', 'gender_other']:\n",
    "        loanapp[r[5:] + '_' + g[7:]] = loanapp[r] * loanapp[g]\n",
    "\n",
    "# drop unneeded dummy variables\n",
    "loanapp.drop(columns=['race_black', 'race_hispan', 'race_white','gender_female', 'gender_male', 'gender_other'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove .0 portion of string in categorical column names that causes patsy design matrix error\n",
    "for i in list(range(1,len(loanapp.columns))):\n",
    "    if loanapp.columns[i][-2:] == '.0':\n",
    "        loanapp.rename(columns = {loanapp.columns[i] : loanapp.columns[i][:-2]}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demean and standardize variables for later interactions\n",
    "for i in loanapp.columns:\n",
    "    loanapp[i + '_dmean'] = loanapp[i] - loanapp[i].mean(skipna = True)\n",
    "    if i[-6:] != '_dmean':\n",
    "        loanapp[i + '_standard'] = (loanapp[i] - loanapp[i].mean(skipna = True)) / loanapp[i].var(skipna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Function\n",
    "\n",
    "To reduce the amount of copying and pasting of the Ridge, LASSO, and Elastic regression code, I decided to construct a function that runs the three regressions where the input is the dataset and the specification to check, and the output is the coefficients in each regression and the mean squared error of the testing set prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that collects shrinkage method regression coefficients and collects test MSE\n",
    "\n",
    "def runshrinkages(specification, df):\n",
    "    # create design matrix\n",
    "    y, X = patsy.dmatrices(specification, data = df, return_type = 'dataframe')\n",
    "\n",
    "    # create the indices for the train (80%) and validation (20%) data sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # create a dataframe that collects the coeficients from different regressions\n",
    "    shrink_coefs = pd.DataFrame(columns = ['Ridge', 'LASSO', 'Elastic'], index = X.columns)\n",
    "\n",
    "    # create a dataframe that collects mean square error (MSE) from each test\n",
    "    mse_df = pd.DataFrame(columns = ['MSE'], index = ['Ridge', 'LASSO', 'Elastic'])\n",
    "\n",
    "    # Ridge Regression\n",
    "    # create array of alphas for cross-validation alpha selection\n",
    "    alphas = np.linspace(0,0.05,20) + 0.001\n",
    "    \n",
    "    # use cross-validation ridge regression function to choose alpha for ridge regression\n",
    "    ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "    ridgecv.set_params(fit_intercept=True)\n",
    "    ridgecv.fit(X_train, y_train)\n",
    "\n",
    "    # run ridge regression to fit training set, predict testing set, and extract MSE from prediction\n",
    "    ridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "    ridge.set_params(fit_intercept=True)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    mse_df['MSE'][0] = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "\n",
    "    # find ridge shrinkage coefficients of specification\n",
    "    ridge.fit(X,y)\n",
    "    shrink_coefs[['Ridge']] = ridge.coef_.transpose(1,0).tolist()\n",
    "\n",
    "    # Lasso Regression\n",
    "    # use cross-validation LASSO regression function to choose alpha for LASSO regression\n",
    "    alphas = np.linspace(0.0001,0.0005,100)\n",
    "    lassocv = LassoCV(alphas = list(alphas), cv = 10, max_iter = 100000, normalize = True)\n",
    "    lassocv.set_params(fit_intercept=True)\n",
    "    lassocv.fit(X_train, y_train.values.ravel()) # avoid warning using ravel()\n",
    "\n",
    "    # run LASSO regression to fit training set, predict testing set, and extract MSE from prediction\n",
    "    lasso = Lasso(max_iter = 10000, normalize = True)\n",
    "    lasso.set_params(alpha=lassocv.alpha_, fit_intercept=True)\n",
    "    lasso.fit(X_train, y_train.values.ravel())\n",
    "    mse_df['MSE'][1] = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "\n",
    "    # find LASSO shrinkage coefficients of specification\n",
    "    lasso.fit(X,y)\n",
    "    shrink_coefs['LASSO'] = lasso.coef_.tolist()\n",
    "\n",
    "    # Elastic Net\n",
    "    # use cross-validation Elastic Net regression function to choose alpha and L1 ratio for Elastic Net regression\n",
    "    enetcv = ElasticNetCV(cv=10, random_state=42, fit_intercept=True, normalize = True)\n",
    "    enetcv.fit(X_train, y_train.values.ravel()) # need .ravel() to avoid warning\n",
    "    \n",
    "    # run elastic regression to fit training set, predict testing set, and extract MSE from prediction\n",
    "    enet = ElasticNet(alpha=enetcv.alpha_, l1_ratio=enetcv.l1_ratio_, fit_intercept=True)\n",
    "    enet.fit(X_train, y_train)\n",
    "    mse_df['MSE'][2] = mean_squared_error(y_test, enet.predict(X_test))\n",
    "\n",
    "    # find elastic net shrinkage coefficients of specification\n",
    "    enet.fit(X, y)\n",
    "    shrink_coefs['Elastic'] = enet.coef_.tolist()\n",
    "\n",
    "    return {'mse': mse_df, 'coefs' : shrink_coefs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment:\n",
    "\n",
    "You standardized the model before but in the options of  Ridge, LASSO, and Elastic regression you chose ```normalized = True```. In the web-page of the library the authors say:  If you wish to standardize, please use ```sklearn.preprocessing.StandardScaler``` before calling fit on an estimator with ```normalize=False```. You standardize the data yourself but it still applies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Base Model\n",
    "\n",
    "In Hunter and Walker's $\\textit{The Cultural Gap Hypothesis and Mortgage Lending Decision}$, the authors constructed a model with variables they found to be the most optimal. Therefore, I decided to construct their model first and observe what their mean squared error results are for their proposed model. In the next section, I will aim to construct a model that has a lower MSE than the paper's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper Model Specification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'approve_1 ~ -1 + hrat + obrat + mortlat2_1 + pubrec_1 + self_1 + chist_1 + unem + multi_1 + cosign_1 + married_1 + loanprc + dep + sch_1 + thick_1 + white_1 + male_1 + vr_1 + sch_1:white_1 + sch_1:male_1 + sch_1:thick_1 + sch_1:vr_1 + chist_1:white_1 + chist_1:male_1 + chist_1:thick_1 + chist_1:vr_1 + obrat:male_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of variables in paper specification\n",
    "paper = ['hrat', 'obrat', 'mortlat2_1', 'pubrec_1', 'self_1', 'chist_1', 'unem', 'multi_1', 'cosign_1', 'married_1', 'loanprc', 'dep', 'sch_1', 'thick_1', 'white_1', 'male_1', 'vr_1']\n",
    "\n",
    "# build model based on paper specification\n",
    "f = 'approve_1 ~ -1 + ' + ' + '.join([ x for x in paper]) + ' + sch_1:white_1 + sch_1:male_1 + sch_1:thick_1 + sch_1:vr_1 + chist_1:white_1 + chist_1:male_1 + chist_1:thick_1 + chist_1:vr_1 + obrat:male_1'\n",
    "\n",
    "# print resulting model specification\n",
    "print('Paper Model Specification')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper MSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0953132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.0942892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.0961222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE\n",
       "Ridge    0.0953132\n",
       "LASSO    0.0942892\n",
       "Elastic  0.0961222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the shrinkage function\n",
    "paper_model = runshrinkages(f, loanapp)\n",
    "\n",
    "# print the MSE of each shrinkage regression\n",
    "print('Paper MSE')\n",
    "paper_model['mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper Coefficients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>Elastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hrat</td>\n",
       "      <td>0.00125201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>obrat</td>\n",
       "      <td>-0.00514317</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>-0.007279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1</td>\n",
       "      <td>-0.103042</td>\n",
       "      <td>-0.060581</td>\n",
       "      <td>-0.090278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pubrec_1</td>\n",
       "      <td>-0.231903</td>\n",
       "      <td>-0.231685</td>\n",
       "      <td>-0.234832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>self_1</td>\n",
       "      <td>-0.0408941</td>\n",
       "      <td>-0.027214</td>\n",
       "      <td>-0.043405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1</td>\n",
       "      <td>0.163122</td>\n",
       "      <td>0.124461</td>\n",
       "      <td>0.253122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unem</td>\n",
       "      <td>-0.00598244</td>\n",
       "      <td>-0.004293</td>\n",
       "      <td>-0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multi_1</td>\n",
       "      <td>-0.0739748</td>\n",
       "      <td>-0.063757</td>\n",
       "      <td>-0.071716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cosign_1</td>\n",
       "      <td>0.0231465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1</td>\n",
       "      <td>0.0400116</td>\n",
       "      <td>0.023811</td>\n",
       "      <td>0.042206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loanprc</td>\n",
       "      <td>-0.141075</td>\n",
       "      <td>-0.119311</td>\n",
       "      <td>-0.142137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dep</td>\n",
       "      <td>-0.0062722</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1</td>\n",
       "      <td>-0.000975612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thick_1</td>\n",
       "      <td>-0.0548576</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.061972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>white_1</td>\n",
       "      <td>0.160957</td>\n",
       "      <td>0.114508</td>\n",
       "      <td>0.244655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>male_1</td>\n",
       "      <td>-0.0366559</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.107335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vr_1</td>\n",
       "      <td>0.00226959</td>\n",
       "      <td>-0.009684</td>\n",
       "      <td>0.024087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:white_1</td>\n",
       "      <td>-0.0237621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.056963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:male_1</td>\n",
       "      <td>0.0351414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:thick_1</td>\n",
       "      <td>0.0683989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:vr_1</td>\n",
       "      <td>-0.0344991</td>\n",
       "      <td>-0.012609</td>\n",
       "      <td>-0.041892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:white_1</td>\n",
       "      <td>-0.0387211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.112961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:male_1</td>\n",
       "      <td>-0.00418427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:thick_1</td>\n",
       "      <td>0.00724336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:vr_1</td>\n",
       "      <td>-0.00574021</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.024422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>obrat:male_1</td>\n",
       "      <td>0.000204693</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.002340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ridge     LASSO   Elastic\n",
       "hrat              0.00125201  0.000000  0.001615\n",
       "obrat            -0.00514317 -0.003981 -0.007279\n",
       "mortlat2_1         -0.103042 -0.060581 -0.090278\n",
       "pubrec_1           -0.231903 -0.231685 -0.234832\n",
       "self_1            -0.0408941 -0.027214 -0.043405\n",
       "chist_1             0.163122  0.124461  0.253122\n",
       "unem             -0.00598244 -0.004293 -0.006317\n",
       "multi_1           -0.0739748 -0.063757 -0.071716\n",
       "cosign_1           0.0231465  0.000000  0.027631\n",
       "married_1          0.0400116  0.023811  0.042206\n",
       "loanprc            -0.141075 -0.119311 -0.142137\n",
       "dep               -0.0062722 -0.000000 -0.006689\n",
       "sch_1           -0.000975612  0.000000  0.008906\n",
       "thick_1           -0.0548576 -0.000000 -0.061972\n",
       "white_1             0.160957  0.114508  0.244655\n",
       "male_1            -0.0366559 -0.000000 -0.107335\n",
       "vr_1              0.00226959 -0.009684  0.024087\n",
       "sch_1:white_1     -0.0237621  0.000000 -0.056963\n",
       "sch_1:male_1       0.0351414  0.000000  0.057415\n",
       "sch_1:thick_1      0.0683989  0.000000  0.085905\n",
       "sch_1:vr_1        -0.0344991 -0.012609 -0.041892\n",
       "chist_1:white_1   -0.0387211  0.000000 -0.112961\n",
       "chist_1:male_1   -0.00418427  0.000000 -0.026406\n",
       "chist_1:thick_1   0.00724336  0.000000 -0.000000\n",
       "chist_1:vr_1     -0.00574021 -0.000000 -0.024422\n",
       "obrat:male_1     0.000204693 -0.000000  0.002340"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the shrinkage coefficients of the model\n",
    "print('Paper Coefficients')\n",
    "paper_model['coefs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression with the lowest mean squared error (MSE) is LASSO. Therefore, based on LASSO, the most optimal model is the following:\n",
    "\n",
    "$approve$ = $\\beta_0$ + $\\beta_1$ $obrat$ + $\\beta_2$ $mortlat2\\_1$ + $\\beta_3$ $pubrec\\_1$ + $\\beta_4$ $self\\_1$ + $\\beta_5$ $chist\\_1$ + $\\beta_6$ $unem$ + $\\beta_7$ $multi\\_1$ + $\\beta_8$ $married\\_1$ + $\\beta_9$ $loanprc$ + $\\beta_{10}$ $white\\_1$ + $\\beta_{11}$ $vr\\_1$ + $\\beta_{12}$ $sch\\_1:vr\\_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated Model Specifications\n",
    "\n",
    "With the shrinkage model results from the previous section, I will now build off of the base paper model by adding race and gender intersection dummy variables and adding interactions between race/gender dummy variables and other variables I've deemed possibly relevant. After testing the model with the race/gender and their interactions, I will take those same variables and demean and standardize them in two different models to see if the mean square error decreases. In total, I will construct three more models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing the race and gender variables and their demenaed and standardize counterparts\n",
    "race_gender = ['black_female', 'black_male', 'black_other', 'hispan_female', 'hispan_male', 'hispan_other', 'white_female', 'white_other']\n",
    "\n",
    "race_gender_dmean = ['black_female_dmean', 'black_male_dmean', 'black_other_dmean', 'hispan_female_dmean', 'hispan_male_dmean', 'hispan_other_dmean', 'white_female_dmean', 'white_other_dmean']\n",
    "\n",
    "race_gender_standard = ['black_female_dmean', 'black_male_dmean', 'black_other_dmean', 'hispan_female_dmean', 'hispan_male_dmean', 'hispan_other_dmean', 'white_female_dmean', 'white_other_dmean']\n",
    "\n",
    "# loop through the married, unverified info, and late mortgage payments variables and create list of the interactions with race/gender\n",
    "race_gender_interact = []\n",
    "for i in ['married_1', 'unver_1', 'mortlat2_1']:\n",
    "    for rg in race_gender:\n",
    "        race_gender_interact.append(i + ':' + rg)\n",
    "\n",
    "race_gender_interact_dmean = []\n",
    "for i in ['married_1_dmean', 'unver_1_dmean', 'mortlat2_1_dmean']:\n",
    "    for rg in race_gender_dmean:\n",
    "        race_gender_interact_dmean.append(i + ':' + rg)\n",
    "\n",
    "race_gender_interact_standard = []\n",
    "for i in ['married_1_standard', 'unver_1_standard', 'mortlat2_1_standard']:\n",
    "    for rg in race_gender_standard:\n",
    "        race_gender_interact_standard.append(i + ':' + rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string specification for regular model\n",
    "g = f + ' + ' + ' + '.join([x for x in race_gender]) + ' + ' + ' + '.join([x for x in race_gender_interact])\n",
    "\n",
    "# create string specification for demeaned model \n",
    "g_dmean = f + ' + ' + ' + '.join([x for x in race_gender_dmean]) + ' + ' + ' + '.join([x for x in race_gender_interact_dmean])\n",
    "\n",
    "# create string specification for standard model\n",
    "g_standard = f + ' + ' + ' + '.join([x for x in race_gender_standard]) + ' + ' + ' + '.join([x for x in race_gender_interact_standard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** god job! I like the idea of the function it allows to test may different models faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Shrinkage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0860434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.0863096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.0876498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE\n",
       "Ridge    0.0860434\n",
       "LASSO    0.0863096\n",
       "Elastic  0.0876498"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run shrinkage methods for regular specification and print MSE\n",
    "regular = runshrinkages(g, loanapp)\n",
    "print('Regular Shrinkage')\n",
    "regular['mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demeaned Shrinkage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0837909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.0933818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.0946233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE\n",
       "Ridge    0.0837909\n",
       "LASSO    0.0933818\n",
       "Elastic  0.0946233"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run shrinkage methods for demeaned specification and print MSE\n",
    "demeaned = runshrinkages(g_dmean, loanapp)\n",
    "print('Demeaned Shrinkage')\n",
    "demeaned['mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Shrinkage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.0837909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.0933818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic</td>\n",
       "      <td>0.0904258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE\n",
       "Ridge    0.0837909\n",
       "LASSO    0.0933818\n",
       "Elastic  0.0904258"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run shrinkage methods for standard specification and print MSE\n",
    "standard = runshrinkages(g_standard, loanapp)\n",
    "print('Standard Shrinkage')\n",
    "standard['mse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the three specifications, the regular shrinkage has all three MSEs in the same range (0.086-0.086), but the demeaned and standard ridge shrinkages have the lowest MSE of 0.0837909. However, their LASSO and Elastic has a higher MSE than the standard shrinkage MSEs. Therefore, I would find that the standard Ridge and LASSO specification would be the best reference points to build the best model for the clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Model Specification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'approve_1 ~ -1 + hrat + obrat + mortlat2_1 + pubrec_1 + self_1 + chist_1 + unem + multi_1 + cosign_1 + married_1 + loanprc + dep + sch_1 + thick_1 + white_1 + male_1 + vr_1 + sch_1:white_1 + sch_1:male_1 + sch_1:thick_1 + sch_1:vr_1 + chist_1:white_1 + chist_1:male_1 + chist_1:thick_1 + chist_1:vr_1 + obrat:male_1 + black_female + black_male + black_other + hispan_female + hispan_male + hispan_other + white_female + white_other + married_1:black_female + married_1:black_male + married_1:black_other + married_1:hispan_female + married_1:hispan_male + married_1:hispan_other + married_1:white_female + married_1:white_other + unver_1:black_female + unver_1:black_male + unver_1:black_other + unver_1:hispan_female + unver_1:hispan_male + unver_1:hispan_other + unver_1:white_female + unver_1:white_other + mortlat2_1:black_female + mortlat2_1:black_male + mortlat2_1:black_other + mortlat2_1:hispan_female + mortlat2_1:hispan_male + mortlat2_1:hispan_other + mortlat2_1:white_female + mortlat2_1:white_other'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the regular specification that was used for shrinkages for reference\n",
    "print('Regular Model Specification')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Coefficients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>Elastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>hrat</td>\n",
       "      <td>0.00128465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>obrat</td>\n",
       "      <td>-0.00525866</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.007039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1</td>\n",
       "      <td>-0.0357315</td>\n",
       "      <td>-0.006939</td>\n",
       "      <td>-0.051918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pubrec_1</td>\n",
       "      <td>-0.219244</td>\n",
       "      <td>-0.215262</td>\n",
       "      <td>-0.223996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>self_1</td>\n",
       "      <td>-0.043566</td>\n",
       "      <td>-0.022992</td>\n",
       "      <td>-0.044695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1</td>\n",
       "      <td>0.124696</td>\n",
       "      <td>0.109440</td>\n",
       "      <td>0.183596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unem</td>\n",
       "      <td>-0.00580628</td>\n",
       "      <td>-0.003201</td>\n",
       "      <td>-0.005970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>multi_1</td>\n",
       "      <td>-0.0723511</td>\n",
       "      <td>-0.057426</td>\n",
       "      <td>-0.072468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cosign_1</td>\n",
       "      <td>0.0346143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1</td>\n",
       "      <td>0.0473033</td>\n",
       "      <td>0.017477</td>\n",
       "      <td>0.049739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loanprc</td>\n",
       "      <td>-0.125854</td>\n",
       "      <td>-0.106060</td>\n",
       "      <td>-0.128406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dep</td>\n",
       "      <td>-0.00628041</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.007326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1</td>\n",
       "      <td>-0.000811324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thick_1</td>\n",
       "      <td>-0.0640074</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.073567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>white_1</td>\n",
       "      <td>0.0465891</td>\n",
       "      <td>0.066585</td>\n",
       "      <td>0.119796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>male_1</td>\n",
       "      <td>-0.0246255</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.110473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vr_1</td>\n",
       "      <td>0.000735228</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.014499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:white_1</td>\n",
       "      <td>-0.0201423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:male_1</td>\n",
       "      <td>0.0273352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:thick_1</td>\n",
       "      <td>0.0845775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sch_1:vr_1</td>\n",
       "      <td>-0.0331167</td>\n",
       "      <td>-0.007704</td>\n",
       "      <td>-0.037276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:white_1</td>\n",
       "      <td>-0.0168161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.059434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:male_1</td>\n",
       "      <td>0.00430662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:thick_1</td>\n",
       "      <td>0.00687812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chist_1:vr_1</td>\n",
       "      <td>-0.00449443</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.017153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>obrat:male_1</td>\n",
       "      <td>2.07938e-05</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.001738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>black_female</td>\n",
       "      <td>-0.0590106</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.057035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>black_male</td>\n",
       "      <td>-0.00955616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>black_other</td>\n",
       "      <td>0.0194374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hispan_female</td>\n",
       "      <td>-0.0661288</td>\n",
       "      <td>-0.027986</td>\n",
       "      <td>-0.061595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hispan_male</td>\n",
       "      <td>-0.0524627</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.018217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hispan_other</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>white_female</td>\n",
       "      <td>0.0432262</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.006443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>white_other</td>\n",
       "      <td>0.0963408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:black_female</td>\n",
       "      <td>0.0193608</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:black_male</td>\n",
       "      <td>-0.0187426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:black_other</td>\n",
       "      <td>0.0194374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:hispan_female</td>\n",
       "      <td>-0.123654</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>-0.114014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:hispan_male</td>\n",
       "      <td>0.00684756</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:hispan_other</td>\n",
       "      <td>0.000186866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:white_female</td>\n",
       "      <td>-0.0228691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>married_1:white_other</td>\n",
       "      <td>-0.0347364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:black_female</td>\n",
       "      <td>-0.197121</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.064104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:black_male</td>\n",
       "      <td>-0.735245</td>\n",
       "      <td>-0.617495</td>\n",
       "      <td>-0.703031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:black_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:hispan_female</td>\n",
       "      <td>-0.473868</td>\n",
       "      <td>-0.372292</td>\n",
       "      <td>-0.438060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:hispan_male</td>\n",
       "      <td>-0.648403</td>\n",
       "      <td>-0.573276</td>\n",
       "      <td>-0.629909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:hispan_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:white_female</td>\n",
       "      <td>-0.35855</td>\n",
       "      <td>-0.260923</td>\n",
       "      <td>-0.352490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unver_1:white_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:black_female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:black_male</td>\n",
       "      <td>-0.728569</td>\n",
       "      <td>-0.391538</td>\n",
       "      <td>-0.398611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:black_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:hispan_female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:hispan_male</td>\n",
       "      <td>-0.335305</td>\n",
       "      <td>-0.170020</td>\n",
       "      <td>-0.210479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:hispan_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:white_female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mortlat2_1:white_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Ridge     LASSO   Elastic\n",
       "hrat                       0.00128465  0.000000  0.001630\n",
       "obrat                     -0.00525866 -0.003931 -0.007039\n",
       "mortlat2_1                 -0.0357315 -0.006939 -0.051918\n",
       "pubrec_1                    -0.219244 -0.215262 -0.223996\n",
       "self_1                      -0.043566 -0.022992 -0.044695\n",
       "chist_1                      0.124696  0.109440  0.183596\n",
       "unem                      -0.00580628 -0.003201 -0.005970\n",
       "multi_1                    -0.0723511 -0.057426 -0.072468\n",
       "cosign_1                    0.0346143  0.000000  0.037609\n",
       "married_1                   0.0473033  0.017477  0.049739\n",
       "loanprc                     -0.125854 -0.106060 -0.128406\n",
       "dep                       -0.00628041 -0.000000 -0.007326\n",
       "sch_1                    -0.000811324  0.000000  0.000000\n",
       "thick_1                    -0.0640074 -0.000000 -0.073567\n",
       "white_1                     0.0465891  0.066585  0.119796\n",
       "male_1                     -0.0246255 -0.000000 -0.110473\n",
       "vr_1                      0.000735228 -0.009341  0.014499\n",
       "sch_1:white_1              -0.0201423  0.000000 -0.028841\n",
       "sch_1:male_1                0.0273352  0.000000  0.034847\n",
       "sch_1:thick_1               0.0845775  0.000000  0.103819\n",
       "sch_1:vr_1                 -0.0331167 -0.007704 -0.037276\n",
       "chist_1:white_1            -0.0168161  0.000000 -0.059434\n",
       "chist_1:male_1             0.00430662  0.000000 -0.011217\n",
       "chist_1:thick_1            0.00687812  0.000000  0.000000\n",
       "chist_1:vr_1              -0.00449443 -0.000000 -0.017153\n",
       "obrat:male_1              2.07938e-05 -0.000000  0.001738\n",
       "black_female               -0.0590106 -0.000000 -0.057035\n",
       "black_male                -0.00955616  0.000000  0.000000\n",
       "black_other                 0.0194374  0.000000  0.000000\n",
       "hispan_female              -0.0661288 -0.027986 -0.061595\n",
       "hispan_male                -0.0524627 -0.000000 -0.018217\n",
       "hispan_other                 0.116221  0.000000  0.005935\n",
       "white_female                0.0432262  0.002905  0.006443\n",
       "white_other                 0.0963408  0.000000  0.027243\n",
       "married_1:black_female      0.0193608 -0.000000  0.000000\n",
       "married_1:black_male       -0.0187426  0.000000 -0.000934\n",
       "married_1:black_other       0.0194374  0.000000  0.000000\n",
       "married_1:hispan_female     -0.123654 -0.026840 -0.114014\n",
       "married_1:hispan_male      0.00684756 -0.000000  0.008125\n",
       "married_1:hispan_other    0.000186866  0.000000  0.000000\n",
       "married_1:white_female     -0.0228691  0.000000 -0.025854\n",
       "married_1:white_other      -0.0347364  0.000000 -0.000000\n",
       "unver_1:black_female        -0.197121 -0.000000 -0.064104\n",
       "unver_1:black_male          -0.735245 -0.617495 -0.703031\n",
       "unver_1:black_other                 0  0.000000  0.000000\n",
       "unver_1:hispan_female       -0.473868 -0.372292 -0.438060\n",
       "unver_1:hispan_male         -0.648403 -0.573276 -0.629909\n",
       "unver_1:hispan_other                0  0.000000  0.000000\n",
       "unver_1:white_female         -0.35855 -0.260923 -0.352490\n",
       "unver_1:white_other                 0  0.000000  0.000000\n",
       "mortlat2_1:black_female             0  0.000000  0.000000\n",
       "mortlat2_1:black_male       -0.728569 -0.391538 -0.398611\n",
       "mortlat2_1:black_other              0  0.000000  0.000000\n",
       "mortlat2_1:hispan_female            0  0.000000  0.000000\n",
       "mortlat2_1:hispan_male      -0.335305 -0.170020 -0.210479\n",
       "mortlat2_1:hispan_other             0  0.000000  0.000000\n",
       "mortlat2_1:white_female             0  0.000000  0.000000\n",
       "mortlat2_1:white_other              0  0.000000  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the coefficients for the regular shrinkage model results\n",
    "print('Regular Coefficients')\n",
    "regular['coefs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final model I would propose to the client:\n",
    "\n",
    "$approve$ = $\\beta_1$ $obrat$ + $\\beta_2$ $mortlat2\\_1$ + $\\beta_3$ $pubrec\\_1$ + $\\beta_4$ $self\\_1$ + $\\beta_5$ $chist\\_1$ + $\\beta_6$ $unem$ + $\\beta_7$ $multi\\_1$ + $\\beta_8$ $married\\_1$ + $\\beta_9$ $loanprc$ + $\\beta_{10}$ $white\\_1$ + $\\beta_{11}$ $vr\\_1$ + $\\beta_{12}$ $sch\\_1:vr\\_1$ + $\\beta_{13}$ $hispan\\_female$ + $\\beta_{14}$ $white\\_female$ + $\\beta_{15}$ $married\\_1:hispan\\_female$ + $\\beta_{16}$ $unver\\_1:black\\_male$ + $\\beta_{17}$ $unver\\_1:hispan\\_female$ + $\\beta_{17}$ $unver\\_1:hispan\\_male$ + $\\beta_{18}$ $unver\\_1:white\\_female$ + $\\beta_{19}$ $mortlat2\\_1:black\\_male$ + $\\beta_{20}$ $mortlat2\\_1:hispan\\_male$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
