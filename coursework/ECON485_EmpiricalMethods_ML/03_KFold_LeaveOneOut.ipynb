{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Empirical Assignment 3</h1></center>\n",
    "\n",
    "**Author(s):**\n",
    "1. Belicia Rodriguez (belicia.rodriguez@emory.edu)\n",
    "\n",
    "**Objectives**: This <ins>assignment</ins> aims at\n",
    " 1. Familiarizing you with *sampling techniques* using the ```pandas``` and ```sklearn``` Python libraries;\n",
    " 2. Use *GitHub* to retrieve and submit computer code.\n",
    "\n",
    "**Instructions**:\n",
    " 1. Read this post https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 before attempting to answer these questions.\n",
    " 2. Please write down your Python code and <ins>execute</ins> it in the cell below each question.\n",
    " \n",
    "<center><h2> Questions</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [5 points] Using the ```read_stata``` function from the ```pandas``` library in Python, download the ```ceosal2``` used in Assignment 1 using the address ```http://fmwww.bc.edu/ec-p/data/wooldridge/ceosal2.dta```. **Note:** You need a working connection to the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load ceosal2 \n",
    "ceosal2 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/ceosal2.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [5 points] Verify that there are 94 CEOs who went to graduate school in your sample, i.e., 53.1073% of your sample, and that there are 172 CEOs with some college education, i.e., 97.175%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEOs who went to graduate school\n",
      "94\n",
      "0.53107\n",
      "CEOs who have some college\n",
      "172\n",
      "0.97175\n"
     ]
    }
   ],
   "source": [
    "# initialize empty array\n",
    "df = []\n",
    "\n",
    "# verifying 94 CEOs went to grad school\n",
    "ceo_grad = (ceosal2.grad == 1).sum()\n",
    "ceo_grad_perc = round(ceosal2['grad'].mean(),5)\n",
    "\n",
    "\n",
    "# verifying 172 CEOs have some college\n",
    "ceo_college = (ceosal2.college == 1).sum()\n",
    "ceo_college_perc = round(ceosal2['college'].mean(),5)\n",
    "\n",
    "# print information\n",
    "print('CEOs who went to graduate school')\n",
    "print(ceo_grad)\n",
    "print(ceo_grad_perc)\n",
    "\n",
    "print('CEOs who have some college')\n",
    "print(ceo_college)\n",
    "print(ceo_college_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [15 points] Importing the ```KFold``` function from ```sklearn.model_selection``` make 5 folds of the data with the seed equal to 42 and print the same two proportions of CEOs in the previous questions in each folds i.e the two proportions in the training and the two proportions in the test data sets. **Hint:** (1) Read https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html; (2) Use the ```to_numpy()``` function from the ```pandas``` library, and/or the ```iloc``` function for ```pandas``` data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "   Fold College Training College Testing Grad Training Grad Testing\n",
      "0     1         0.978723        0.944444      0.546099     0.472222\n",
      "1     2         0.964539               1       0.51773     0.583333\n",
      "2     3         0.971831        0.971429      0.528169     0.542857\n",
      "3     4         0.978873        0.942857      0.535211     0.514286\n",
      "4     5         0.964789               1      0.528169     0.542857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# covert ceosal2 from dataframe to array\n",
    "ceosal2_array = ceosal2.to_numpy()\n",
    "\n",
    "# create kfold object\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(kf)\n",
    "\n",
    "# create dataframe for storing the folds info\n",
    "d = {'Fold' : [1,2,3,4,5], 'College Training' : [None] * 5, 'College Testing' : [None] * 5,\n",
    "     'Grad Training': [None] * 5, 'Grad Testing': [None] * 5}\n",
    "fold_df = pd.DataFrame(data = d)\n",
    "\n",
    "# initiate counter for loop\n",
    "i = 0\n",
    "\n",
    "# split data into five folds\n",
    "for train_index, test_index in kf.split(ceosal2_array):\n",
    "    # divide dataframe into test and train\n",
    "    ceo_xtrain = ceosal2.iloc[train_index]\n",
    "    ceo_xtest = ceosal2.iloc[test_index]\n",
    "    \n",
    "    # store number of CEOS who went to college in each fold test ant training set\n",
    "    fold_df.loc[i,['College Training']] = (ceo_xtrain.college).mean()\n",
    "    fold_df.loc[i,['College Testing']] = (ceo_xtest.college).mean()\n",
    "    fold_df.loc[i, ['Grad Training']] = (ceo_xtrain.grad).mean()\n",
    "    fold_df.loc[i, ['Grad Testing']] = (ceo_xtest.grad).mean()\n",
    "    \n",
    "    # add to counter\n",
    "    i = i + 1\n",
    "\n",
    "# print dataframe with results\n",
    "print(fold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [5 points] Verify that in some of the 5 folds of the data you constructed before there are _no_ CEOs with *no* college education in either the train or the test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [salary, age, college, grad, comten, ceoten, sales, profits, mktval, lsalary, lsales, lmktval, comtensq, ceotensq, profmarg]\n",
      "Index: []\n",
      "There are no observations where there are no CEOs with no college education.\n"
     ]
    }
   ],
   "source": [
    "print(ceosal2[(ceosal2.college == 0) & (ceosal2.ceoten == 0)])\n",
    "\n",
    "print('There are no observations where there are no CEOs with no college education.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [70 points] Estimate the following model\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\texttt{lsalary} = \\beta_0+\\beta_1\\texttt{lsales}+\\beta_2\\texttt{lmktval}+\\beta_3\\texttt{profmarg}+\\beta_4\\texttt{comten}+\\beta_5\\texttt{comtensq}+\\beta_6\\texttt{ceoten}+\\beta_7\\texttt{ceotensq}+\\beta_8\\texttt{age}+\\beta_9\\texttt{college}+\\beta_{10}\\texttt{grad}+e,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "by the OLS estimator. Let $\\widehat{\\beta}_{1,(-i)}$ be the OLS estimator of the parameter $\\beta_1$ in this model obtained by erasing the $i$ observation in the sample, i.e., the leave-one-out estimator of $\\beta_1$. Using the ```LeaveOneOut``` and the ```linear_model``` from the ```sklearn``` library calculate $\\left\\{\\widehat{\\beta}_{1,(-1)},\\widehat{\\beta}_{1,(-2)},\\dots,\\widehat{\\beta}_{1,(-176)},\\widehat{\\beta}_{1,(-177)}\\right\\}$. Then create a histogram of these 177 values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lsalary   R-squared:                       0.382\n",
      "Model:                            OLS   Adj. R-squared:                  0.345\n",
      "Method:                 Least Squares   F-statistic:                     10.27\n",
      "Date:                Wed, 19 Feb 2020   Prob (F-statistic):           2.27e-13\n",
      "Time:                        11:56:33   Log-Likelihood:                -119.40\n",
      "No. Observations:                 177   AIC:                             260.8\n",
      "Df Residuals:                     166   BIC:                             295.7\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.4381      0.451      9.838      0.000       3.548       5.329\n",
      "lsales         0.1858      0.040      4.638      0.000       0.107       0.265\n",
      "lmktval        0.1094      0.049      2.223      0.028       0.012       0.207\n",
      "profmarg      -0.0026      0.002     -1.255      0.211      -0.007       0.002\n",
      "comten        -0.0059      0.012     -0.495      0.621      -0.030       0.018\n",
      "comtensq   -8.356e-05      0.000     -0.320      0.749      -0.001       0.000\n",
      "ceoten         0.0480      0.014      3.338      0.001       0.020       0.076\n",
      "ceotensq      -0.0011      0.000     -2.346      0.020      -0.002      -0.000\n",
      "age            0.0004      0.005      0.080      0.937      -0.010       0.011\n",
      "college       -0.0217      0.231     -0.094      0.925      -0.478       0.434\n",
      "grad          -0.1092      0.078     -1.392      0.166      -0.264       0.046\n",
      "==============================================================================\n",
      "Omnibus:                       27.818   Durbin-Watson:                   2.019\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              142.896\n",
      "Skew:                          -0.335   Prob(JB):                     9.35e-32\n",
      "Kurtosis:                       7.350   Cond. No.                     1.14e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.14e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import patsy\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import sklearn.model_selection as sks\n",
    "import sklearn.linear_model as skm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define a string with regression equation\n",
    "eq = 'lsalary ~ lsales + lmktval + profmarg + comten + comtensq + ceoten + ceotensq + age + college + grad'\n",
    "\n",
    "# build a design matrix with the formula\n",
    "y,X = patsy.dmatrices(eq, data=ceosal2, return_type = 'dataframe')\n",
    "\n",
    "# do OLS regression\n",
    "model = OLS(y,X).fit()\n",
    "\n",
    "# print summary of regression\n",
    "print(model.summary())\n",
    "\n",
    "# create empty list to store LeaveOutOne betas\n",
    "betas = []\n",
    "\n",
    "# run LeaveOneOut cross validation\n",
    "loo = sks.LeaveOneOut()\n",
    "for train, test in loo.split(ceosal2_array):\n",
    "    # run a regression and obtain beta for lsales\n",
    "    beta_value = float((skm.LinearRegression().fit(X.loc[train],y.loc[train]).coef_)[:,1])\n",
    "    \n",
    "    # store beta value as a float\n",
    "    betas.append(beta_value)\n",
    "\n",
    "# create histogram of betas\n",
    "plt.hist(betas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
