{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Case Study 2</h1></center>\n",
    "<center><h3> Week 2 (out of 5)</h3></center>\n",
    "\n",
    "**Author(s):**\n",
    "1. Belicia Rodriguez (belicia.rodriguez@emory.edu)\n",
    " \n",
    "**Data Source**: W.C. Hunter and M.B. Walker (1996), [“*The Cultural Affinity Hypothesis and Mortgage Lending Decisions*,”](https://link.springer.com/article/10.1007/BF00174551) Journal of Real Estate Finance and Economics 13, 57-70.\n",
    " \n",
    "**Book**: [Introductory Econometrics: A Modern Approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) by Jeffrey Wooldridge\n",
    "\n",
    "**Data Description**: ```http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta```\n",
    "\n",
    "```\n",
    "  Obs:  1989\n",
    "\n",
    "  1. occ                       occupancy\n",
    "  2. loanamt                   loan amt in thousands\n",
    "  3. action                    type of action taken\n",
    "  4. msa                       msa number of property\n",
    "  5. suffolk                   =1 if property in Suffolk County\n",
    "  6. race                      race of applicant\n",
    "  7. gender                    gender of applicant\n",
    "  8. appinc                    applicant income, $1000s\n",
    "  9. typur                     type of purchaser of loan\n",
    " 10. unit                      number of units in property\n",
    " 11. married                   =1 if applicant married\n",
    " 12. dep                       number of dependents\n",
    " 13. emp                       years employed in line of work\n",
    " 14. yjob                      years at this job\n",
    " 15. self                      self-employment dummy\n",
    " 16. atotinc                   total monthly income\n",
    " 17. cototinc                  coapp total monthly income\n",
    " 18. hexp                      propose housing expense\n",
    " 19. price                     purchase price\n",
    " 20. other                     other financing, $1000s\n",
    " 21. liq                       liquid assets\n",
    " 22. rep                       no. of credit reports\n",
    " 23. gdlin                     credit history meets guidelines\n",
    " 24. lines                     no. of credit lines on reports\n",
    " 25. mortg                     credit history on mortgage paym\n",
    " 26. cons                      credit history on consumer stuf\n",
    " 27. pubrec                    =1 if filed bankruptcy\n",
    " 28. hrat                      housing exp, % total inccome\n",
    " 29. obrat                     other oblgs,  % total income\n",
    " 30. fixadj                    fixed or adjustable rate?\n",
    " 31. term                      term of loan in months\n",
    " 32. apr                       appraised value\n",
    " 33. prop                      type of property\n",
    " 34. inss                      PMI sought\n",
    " 35. inson                     PMI approved\n",
    " 36. gift                      gift as down payment\n",
    " 37. cosign                    is there a cosigner\n",
    " 38. unver                     unverifiable info\n",
    " 39. review                    number of times reviewed\n",
    " 40. netw                      net worth\n",
    " 41. unem                      unemployment rate by industry\n",
    " 42. min30                     =1 if minority pop. > 30%\n",
    " 43. bd                        =1 if boarded-up val > MSA med\n",
    " 44. mi                        =1 if tract inc > MSA median\n",
    " 45. old                       =1 if applic age > MSA median\n",
    " 46. vr                        =1 if tract vac rte > MSA med\n",
    " 47. sch                       =1 if > 12 years schooling\n",
    " 48. black                     =1 if applicant black\n",
    " 49. hispan                    =1 if applicant Hispanic\n",
    " 50. male                      =1 if applicant male\n",
    " 51. reject                    =1 if action == 3\n",
    " 52. approve                   =1 if action == 1 or 2\n",
    " 53. mortno                    no mortgage history\n",
    " 54. mortperf                  no late mort. payments\n",
    " 55. mortlat1                  one or two late payments\n",
    " 56. mortlat2                  > 2 late payments\n",
    " 57. chist                     =0 if accnts deliq. >= 60 days\n",
    " 58. multi                     =1 if two or more units\n",
    " 59. loanprc                   amt/price\n",
    " 60. thick                     =1 if rep > 2\n",
    " 61. white                     =1 if applicant white\n",
    " 62. obwhte                    obrat*awhite\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [5 points] After loading the data set into a Pandas DataFrame, use the approaches described [here](https://stackoverflow.com/questions/50326157/create-dummy-variables-for-interdependent-categories-in-pandas]) to create dummies for the interdependent race categories `black`, `hispan`, `white` and gender category `male`. **Hint:** You should have generated a total of 6 new dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import dataset as pandas dataframe\n",
    "df = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta')\n",
    "\n",
    "# change numerical values in race and gender to their representation (makes creation of dummy variables easier)\n",
    "df.loc[df.race==5,'race'] = 'white'\n",
    "df.loc[df.race==4,'race'] = 'black'\n",
    "df.loc[df.race==3,'race'] = 'hispan'\n",
    "\n",
    "df.loc[df.gender==1, 'gender'] = 'male'\n",
    "df.loc[df.gender==2, 'gender'] = 'female'\n",
    "df.loc[df.gender==3, 'gender'] = 'other'\n",
    "\n",
    "# create dummies for interdependent race and gender categories\n",
    "df = pd.get_dummies(df, columns = ['race', 'gender'])\n",
    "\n",
    "# create race/gender dummy variables\n",
    "for r in ['race_black', 'race_hispan', 'race_white']:\n",
    "    for g in ['gender_female', 'gender_male', 'gender_other']:\n",
    "        df[r[5:] + '_' + g[7:]] = df[r] * df[g]\n",
    "\n",
    "# drop unneeded dummy variables\n",
    "df.drop(columns=['race_black', 'race_hispan', 'race_white','gender_female', 'gender_male', 'gender_other'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [5 points] Rename the previously 6 newly created dummy variables accordingly, i.e., `black_male` equals 1 for a black male applicant and 0 otherwise, `white_female` equals 1 for a white female applicant and 0 otherwise, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I already renamed the six newly created dummy variables when I changed the numerical values into their string representative and then created their interaction in the for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You are interested in building a model that accurately predict loan rejection (`rejection`) based on various applicants' features such as `loanamt`, `appinc`, `unit`, `married`, `dep`, `emp`, `yjob`, `self`, `atotinc`, `cototinc`, `hexp`, `price`, `other`, `liq`, `rep`, `gdlin`, `lines`, `mortg`, `cons`, `pubrec`, `hrat`, `obrat`, `fixadj`, `term`, `apr`, `gift`, `cosign`, `netw`, `uem`, `min30`, `bd`, `mi`, `old`, `vr`, `sch`, `mortno`, `chist`, `multi`, `loanprc`, `thick`, and 5 of the 6 newly created race-gender dummies, i.e., make the `white_male` the base category.\n",
    "    1. [5 points] Replace *all* the proposed features measured in USD with their natural logarithm.\n",
    "    2. [5 points] *Add* demeaned squared terms of *all* features measured in units of time to your data frame, e.g., `lemp2` where $\\texttt{lemp2}=(\\ln(\\texttt{emp})-\\overline{ln(\\texttt{emp}})^2$ where $\\overline{ln(\\texttt{emp}}$ represents the sample average of the `lemp2` variable. **Note**: You do not need to do this for the remaining features that are not measured in units of time.\n",
    "    3. [10 points] *Add* to your data frame _all_ products between the 5 race-gender dummy variables and the other **non-dummy** features in the data frame so far (including those you created in point B. above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all features of model\n",
    "feat = ['loanamt', 'appinc', 'unit', 'married', 'dep', 'emp', 'yjob', 'self', 'atotinc', 'cototinc', 'hexp', 'price', 'other', 'liq', 'rep', 'gdlin', 'lines', 'mortg', 'cons', 'pubrec', 'hrat', 'obrat', 'fixadj', 'term', 'apr', 'gift', 'cosign', 'netw', 'unem', 'min30', 'bd', 'mi', 'old', 'vr', 'sch', 'mortno', 'chist', 'multi', 'black_male', 'black_female', 'black_other', 'white_female', 'white_other', 'hispan_male', 'hispan_female', 'hispan_other']\n",
    "\n",
    "feat_2 = []\n",
    "\n",
    "# list proposed features measured in US dollars\n",
    "dollars_feat = ['loanamt', 'appinc', 'atotinc', 'cototinc', 'hexp', 'price', 'other', 'liq', 'apr', 'loanprc']\n",
    "\n",
    "# take natural log of dollar features\n",
    "for i in dollars_feat:\n",
    "    for n in range(len(df)):\n",
    "        if df[i][n] > 0:\n",
    "            df[i][n] = np.log(df[i][n])\n",
    "\n",
    "# list features measured in units of time\n",
    "time_feat = ['emp', 'yjob', 'term']\n",
    "\n",
    "# add demeaned squared terms of the time features\n",
    "time_demeaned = []\n",
    "for i in time_feat:\n",
    "    new_var = i + '_dmean_sq'\n",
    "    df[new_var] = (df[i] - df[i].mean(skipna = True))**2\n",
    "\n",
    "    # add new variable to time demeaned list\n",
    "    time_demeaned.append(new_var)\n",
    "\n",
    "# split feat into two lists for race-gender dummy features and other non-dummy features\n",
    "race_gender_feat = ['black_male', 'black_female', 'black_other', 'white_female', 'white_other', 'hispan_male', 'hispan_female', 'hispan_other']\n",
    "\n",
    "non_dummy = ['loanamt', 'appinc', 'unit', 'married', 'dep', 'emp', 'yjob', 'self', 'atotinc', 'cototinc', 'hexp', 'price', 'other', 'liq', 'rep', 'gdlin', 'lines', 'mortg', 'cons', 'pubrec', 'hrat', 'obrat', 'fixadj', 'term', 'apr', 'gift', 'cosign', 'netw', 'unem', 'min30', 'bd', 'mi', 'old', 'vr', 'sch', 'mortno', 'chist', 'multi']\n",
    "\n",
    "# create products of race-gender dummy variables and other non-dummy features in dataframe\n",
    "for i in race_gender_feat:\n",
    "    for j in non_dummy + time_demeaned:\n",
    "        join_str = '*'.join([i,j])\n",
    "        df[join_str] = df[i] * df[j]\n",
    "\n",
    "        # add new variable to features 2 list\n",
    "        feat_2.append(join_str)\n",
    "\n",
    "# add time demeaned to feat_2 list\n",
    "feat_2 = feat_2 + time_demeaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**\n",
    "\n",
    "(2) You could avoid the loop over the idex (which can take long for an increasing number of observations) by finding the variables for which there are zero values using:\n",
    "\n",
    "```zeros = df[usd_terms].loc[:,(df[usd_terms]<=0).any()].columns.tolist()```\n",
    "\n",
    "Then iterating over the variables in the ```zeros``` list to change zeros for ones. With those changes you could iterate over the list ```usd_terms``` and use ```np.log()``` (this does produces the same result as $log(1)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 points] Perform a __Ridge__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed). **Note**: You can do this via the `LogisticRegressionCV` function from the `sklearn.linear_model` subpackage by choosing a suitable set for the `Cs` and `l1_ratios` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string model specification\n",
    "f = 'reject ~ -1 + ' + ' + '.join([x for x in feat + feat_2])\n",
    "\n",
    "# create design matrices for specifications\n",
    "y, X = patsy.dmatrices(f, data=df, return_type='dataframe')\n",
    "\n",
    "# partition dataset into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# standardizes each col of training design matrix \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "# create kfold object\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# create dataframe that will collect scores and optimal alpha and lambdas for each test\n",
    "results = pd.DataFrame(columns=['Scores', 'Lambda', 'Alpha'], index=['Ridge', 'LASSO', 'Elastic Net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.902507</td>\n",
       "      <td>[0.008158]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scores      Lambda Alpha\n",
       "Ridge  0.902507  [0.008158]   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the optimal ridge lambda using cross validation setup\n",
    "searchCV = LogisticRegressionCV(\n",
    "    Cs = list(np.linspace(0.008,0.009,20,endpoint=True))\n",
    "    ,penalty = 'l2'\n",
    "    ,scoring = 'accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv = kfold\n",
    "    ,random_state = 42\n",
    "    ,max_iter = 10000\n",
    "    ,fit_intercept = True\n",
    "    ,solver = 'lbfgs'\n",
    "    ,tol = 10\n",
    ")\n",
    "\n",
    "# fit the cross validation logit regression\n",
    "logitcv = searchCV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# calculate proportion of true predictions\n",
    "results.loc['Ridge', 'Scores'] = logitcv.score(X_test, y_test)\n",
    "\n",
    "# calculate the optimal lambda used\n",
    "results.loc['Ridge', 'Lambda'] = (logitcv.C_).round(6)\n",
    "\n",
    "# show results\n",
    "results.loc[['Ridge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Confusion Matrix: \n",
      " [[312   7]\n",
      " [ 28  12]]\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix of test set\n",
    "ridge_confusion_mat = confusion_matrix(y_test, logitcv.predict(X_test))\n",
    "print('Ridge Confusion Matrix: \\n', ridge_confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [20 points] Perform a __Lasso__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed). **Note:** You can do this via the `LogisticRegressionCV` function from the `sklearn.linear_model` subpackage by choosing a suitable set for the `Cs` and `l1_ratios` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>[0.008053]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Scores      Lambda Alpha\n",
       "LASSO  0.891365  [0.008053]   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the optimal ridge lambda using cross validation setup\n",
    "searchCV = LogisticRegressionCV(\n",
    "    Cs = list(np.linspace(0.008,0.009,20,endpoint=True))\n",
    "    ,penalty = 'l1'\n",
    "    ,scoring = 'accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv = kfold\n",
    "    ,random_state = 42\n",
    "    ,max_iter = 10000\n",
    "    ,fit_intercept = True\n",
    "    ,solver = 'saga'\n",
    "    ,tol = 10\n",
    ")\n",
    "\n",
    "# fit the cross validation logit regression\n",
    "logitcv = searchCV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# calculate proportion of true predictions\n",
    "results.loc['LASSO', 'Scores'] = logitcv.score(X_test, y_test)\n",
    "\n",
    "# calculate the optimal lambda used\n",
    "results.loc['LASSO', 'Lambda'] = (logitcv.C_).round(6)\n",
    "\n",
    "# show results\n",
    "results.loc[['LASSO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Confusion Matrix: \n",
      " [[318   1]\n",
      " [ 38   2]]\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix of test set\n",
    "lasso_confusion_mat = confusion_matrix(y_test, logitcv.predict(X_test))\n",
    "print('LASSO Confusion Matrix: \\n', lasso_confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 points] Perform an __Elastic Net__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.89415</td>\n",
       "      <td>[0.008474]</td>\n",
       "      <td>[0.378694]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Scores      Lambda       Alpha\n",
       "Elastic Net  0.89415  [0.008474]  [0.378694]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the optimal elasticnet alpha and lambda using cross validation setup\n",
    "searchCV = LogisticRegressionCV(\n",
    "    Cs = list(np.linspace(0.007,0.009,20,endpoint=True)) #this corresponds to 1/lambda\n",
    "    ,penalty = 'elasticnet'\n",
    "    ,l1_ratios = np.linspace(0.4,0.05200,endpoint=True) #this corresponds to alpha above\n",
    "    ,scoring = 'accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv = kfold\n",
    "    ,random_state = 42\n",
    "    ,max_iter = 10000\n",
    "    ,fit_intercept = True\n",
    "    ,solver = 'saga' #only optimizer available for elasticnet\n",
    "    ,tol = 10\n",
    ")\n",
    "\n",
    "# fit the cross validation logit regression\n",
    "logitcv = searchCV.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# calculate proportion of true predictions\n",
    "results.loc['Elastic Net', 'Scores'] = logitcv.score(X_test, y_test)\n",
    "\n",
    "# calculate the optimal lambda and alpha used\n",
    "results.loc['Elastic Net', 'Lambda'] = (logitcv.C_).round(6)\n",
    "results.loc['Elastic Net', 'Alpha'] = (logitcv.l1_ratio_).round(6)\n",
    "\n",
    "# show results\n",
    "results.loc[['Elastic Net']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Confusion Matrix: \n",
      " [[307  12]\n",
      " [ 26  14]]\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix of test set\n",
    "elastic_confusion_mat = confusion_matrix(y_test, logitcv.predict(X_test))\n",
    "print('Elastic Net Confusion Matrix: \\n', elastic_confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [10 points] What machine among the three you built would you use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.902507</td>\n",
       "      <td>[0.008158]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LASSO</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>[0.008053]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.89415</td>\n",
       "      <td>[0.008474]</td>\n",
       "      <td>[0.378694]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Scores      Lambda       Alpha\n",
       "Ridge        0.902507  [0.008158]         NaN\n",
       "LASSO        0.891365  [0.008053]         NaN\n",
       "Elastic Net   0.89415  [0.008474]  [0.378694]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results of three logistic regressions for comparison\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Confusion Matrix: \n",
      " [[312   7]\n",
      " [ 28  12]]\n",
      "LASSO Confusion Matrix: \n",
      " [[318   1]\n",
      " [ 38   2]]\n",
      "Elastic Net Confusion Matrix: \n",
      " [[307  12]\n",
      " [ 26  14]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrices\n",
    "print('Ridge Confusion Matrix: \\n', ridge_confusion_mat)\n",
    "print('LASSO Confusion Matrix: \\n', lasso_confusion_mat)\n",
    "print('Elastic Net Confusion Matrix: \\n', elastic_confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use the Ridge Logistical Regression because the regression has the highest proportion of true predictions for the validation set. Ridge has the highest score, meaning Ridge accurately predicted 90% of the loan rejections in the testing set. Also, when comparing the total number of true predictions (adding the diagonals of the confusion matrix) between Ridge, LASSO and Elastic, Ridge has 324 true test set prediction whereas LASSO has 320 and Elastic Net has 321.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
